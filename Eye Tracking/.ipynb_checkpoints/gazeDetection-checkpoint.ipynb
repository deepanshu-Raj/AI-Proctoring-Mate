{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import Success!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from facialLandmarksDetection import *\n",
    "\n",
    "print('import Success!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEyeRegion(landmarks,eyeIndices):\n",
    "    \"\"\"\n",
    "    Input : 68 facial landmark points, Indices of left or right eyes.\n",
    "    Output : region covering respective eye, whose indices have been provided.\n",
    "    \"\"\"\n",
    "    region = []\n",
    "    for i in eyeIndices :\n",
    "        region.append(\n",
    "            (landmarks.part(i).x,landmarks.part(i).y)\n",
    "        )\n",
    "        \n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMask(frame):\n",
    "    \"\"\"\n",
    "    Input : Video capture frame.\n",
    "    Output : A black mask with the size of window's frame\n",
    "    \"\"\"\n",
    "    \n",
    "    height,width,channels = frame.shape\n",
    "    mask = np.zeros((height,width),np.uint8)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEye(mask,region,frame):\n",
    "    \"\"\"\n",
    "    Input : \n",
    "        - mask : A black mask.\n",
    "        - region : list of regions to extract from the frame.\n",
    "        - frame : Video capture frame.\n",
    "    Output : extracted eyes (iris+pupil+sclera)\n",
    "    \"\"\"\n",
    "    #put the polylines on the mask in the right and left eye region\n",
    "    cv2.polylines(mask,region,True,255,2)\n",
    "    cv2.fillPoly(mask,region,255)\n",
    "        \n",
    "    #eyes contains a masked frame for both the eyes.\n",
    "    eyes = cv2.bitwise_and(frame,frame,mask = mask)\n",
    "    return eyes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eyeSegmentationAndReturnWhite(img,side):\n",
    "    \"\"\"\n",
    "    Input : Threshold Image to be Bifercated [into sections] . \n",
    "    Output : White Pixels Count from the bifercated image.\n",
    "    \"\"\"\n",
    "    \n",
    "    height,width = img.shape\n",
    "    if(side=='left'):\n",
    "        img = img[0:height,0:int(width/2)]\n",
    "        return cv2.countNonZero(img)\n",
    "    else:\n",
    "        img = img[0:height,int(width/2):width]\n",
    "        return cv2.countNonZero(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazeDetection(faces,frame):\n",
    "    \"\"\"\n",
    "    Input : list of all the localised faces from the video frame.\n",
    "    Output : frame obtained from the video capture.\n",
    "    \n",
    "    Action : \n",
    "        - Region Extraction.\n",
    "        - Mask Creation.\n",
    "        - Eye Extraction.\n",
    "        - Threshold Application.\n",
    "        - Ratio Calculations For Gaze.\n",
    "    \n",
    "    Display :\n",
    "        - frame with information of no. of white pixels in a region.\n",
    "            ** region is bifercated using a segment bisector, in two equal halves[left and right]\n",
    "            a) upper value represent the pixels of left half.\n",
    "            b) lower value represent the pixels of right half.\n",
    "            \n",
    "        - headings are w.r.t person's original eye. & not w.r.t the cam's view.\n",
    "    \"\"\"\n",
    "    \n",
    "    #indices for the left and the right eye.\n",
    "    #w.r.t camera view.\n",
    "    #w.r.t subject, view is reversed.\n",
    "    right = [36,37,38,39,40,41]\n",
    "    left = [42,43,44,45,46,47]\n",
    "    \n",
    "    for face in faces :\n",
    "        \n",
    "        facialLandmarks = shapePredictor(frame,face)\n",
    "        \n",
    "        \n",
    "        rightEyeRegion = np.array([(facialLandmarks.part(i).x,facialLandmarks.part(i).y) for i in right], np.int32)\n",
    "        leftEyeRegion = np.array([(facialLandmarks.part(i).x,facialLandmarks.part(i).y) for i in left], np.int32)\n",
    "        \n",
    "        #<!--p3-->\n",
    "        \n",
    "        #create the mask of our eye,since the threshold does\n",
    "        #not give us the exact replica of our eye : iris,pupil,sclera.\n",
    "        \n",
    "        mask = createMask(frame)\n",
    "        eyes = extractEye(mask,[rightEyeRegion,leftEyeRegion],frame)\n",
    "        \n",
    "        #extracting the rectangular region covering whole of the eye\n",
    "        #and presenting it on a seperate window.\n",
    "        \n",
    "        rmin_x = np.min(rightEyeRegion[:,0])\n",
    "        rmax_x = np.max(rightEyeRegion[:,0])\n",
    "        rmin_y = np.min(rightEyeRegion[:,1])\n",
    "        rmax_y = np.max(rightEyeRegion[:,1])\n",
    "        \n",
    "        lmin_x = np.min(leftEyeRegion[:,0])\n",
    "        lmax_x = np.max(leftEyeRegion[:,0])\n",
    "        lmin_y = np.min(leftEyeRegion[:,1])\n",
    "        lmax_y = np.max(leftEyeRegion[:,1])\n",
    "        \n",
    "        rightEye = eyes[rmin_y:rmax_y,rmin_x:rmax_x]\n",
    "        leftEye = eyes[lmin_y:lmax_y,lmin_x:lmax_x]\n",
    "        \n",
    "        #converting the normal image to grayscale for applying Threshold.\n",
    "        rightGrayEye = cv2.cvtColor(rightEye,cv2.COLOR_BGR2GRAY)\n",
    "        leftGrayEye = cv2.cvtColor(leftEye,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #THRESHOLD APPLICATION\n",
    "        \n",
    "        #global threshold\n",
    "        #retVal, rightTh = cv2.threshold(rightGrayEye,60,255,cv2.THRESH_BINARY)\n",
    "        #retVal, leftTh = cv2.threshold(leftGrayEye,60,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        #otsu threshold\n",
    "        #retVal, threshold = cv2.threshold(grayEyes,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        \n",
    "        #Adaptive threshold\n",
    "        rightTh = cv2.adaptiveThreshold(rightGrayEye,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        leftTh = cv2.adaptiveThreshold(leftGrayEye,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        \n",
    "        #segments of right eye's threshold\n",
    "        leftSideOfRightTh = eyeSegmentationAndReturnWhite(rightTh,'left')\n",
    "        rightSideOfRightTh = eyeSegmentationAndReturnWhite(rightTh,'right')\n",
    "        #segments of left eye's threshold\n",
    "        leftSideOfLeftTh = eyeSegmentationAndReturnWhite(leftTh,'left')\n",
    "        rightSideOfLeftTh = eyeSegmentationAndReturnWhite(leftTh,'right')\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        thickness = 5\n",
    "        \n",
    "        #for the right eye of the person\n",
    "        cv2.putText(frame,'RIGHT',(50,90),font,2,(0,255,255),thickness)\n",
    "        cv2.putText(frame,str(rightSideOfRightTh),(50,140),font,2,(0,255,255),thickness)\n",
    "        cv2.putText(frame,str(leftSideOfRightTh),(50,190),font,2,(0,255,255),thickness)\n",
    "        \n",
    "        #for the left eye of the person\n",
    "        cv2.putText(frame,'LEFT',(200,90),font,2,(0,255,255),thickness)\n",
    "        cv2.putText(frame,str(rightSideOfLeftTh),(200,140),font,2,(0,255,255),thickness)\n",
    "        cv2.putText(frame,str(leftSideOfLeftTh),(200,190),font,2,(0,255,255),thickness)\n",
    "        \n",
    "        \n",
    "        rightTh = cv2.resize(rightTh,None,fx=10,fy=10)\n",
    "        leftTh = cv2.resize(leftTh,None,fx=10,fy=10)\n",
    "        \n",
    "        cv2.imshow('RIGHT EYE',rightTh)\n",
    "        cv2.imshow('LEFT EYE',leftTh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
